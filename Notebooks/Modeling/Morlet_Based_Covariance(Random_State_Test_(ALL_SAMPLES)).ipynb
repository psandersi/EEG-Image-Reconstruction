{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3a59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing exp_paths: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:00<00:00, 166.49it/s]\n",
      "Loading .fif files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [00:14<00:00, 29.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.chdir('../..')\n",
    "warnings.filterwarnings('ignore')\n",
    "# Firstly import the class of dataset\n",
    "from Scripts.Data_Loader import EIRDataset\n",
    "\n",
    "EIR_Dataset = EIRDataset('./Generated/Data_Train/', task_type='geometric', n_jobs=72) # task type can be `geometric` or `random` or `all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11b8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_df(EIR_Dataset: EIRDataset, freq: int):\n",
    "    for i in range(len(EIR_Dataset)): \n",
    "        eeg_sample, eye_sample, metadata, label, img = EIR_Dataset[i]\n",
    "        eeg_sample.resample(freq)\n",
    "resample_df(EIR_Dataset, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51db7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "loaded = np.load('./Generated/Spectrums/exec_morlets.npz')\n",
    "\n",
    "results_arr = []\n",
    "i = 0\n",
    "while f'power_{i}' in loaded:\n",
    "    power = loaded[f'power_{i}']\n",
    "    phase = loaded[f'phase_{i}']\n",
    "    s_id = int(loaded[f'subject_id_{i}'])\n",
    "    t_id = int(loaded[f'trial_id_{i}'])\n",
    "    gender = str(loaded[f'gender_{i}'])\n",
    "    handiness = str(loaded[f'handiness_{i}'])\n",
    "    age = int(loaded[f'age_{i}'])\n",
    "    label = int(loaded[f'label_{i}'])\n",
    "    img = loaded[f'img_{i}']\n",
    "    task_type = str(loaded[f'task_type_{i}'])\n",
    "    \n",
    "    results_arr.append([power, phase, s_id, t_id, gender, handiness, age, label, img, task_type])\n",
    "    i += 1\n",
    "\n",
    "power, phase, s_id, t_id, gender, handiness, age, label, img, task_type = results_arr[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa60167b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 195, 321)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5528601",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_cluster3 = [7, 7, 9, 9, 14]\n",
    "trial_cluster3 = [2, 1, 2, 1, 1]\n",
    "subjects_cluster4 = [5, 5, 3, 3, 2, 2, 10, 10, 12, 12, 16, 16, 11, 11, 13, 13]\n",
    "trial_cluster4 = [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]\n",
    "selected_trials = trial_cluster3+trial_cluster4\n",
    "selected_subjects= subjects_cluster3+subjects_cluster4\n",
    "power_wav = []\n",
    "phase_wav = []\n",
    "subj = []\n",
    "trial = []\n",
    "label_wav = []\n",
    "tasks = []\n",
    "\n",
    "max_len = 309\n",
    "\n",
    "for i, sample in enumerate(results_arr):\n",
    "\n",
    "    if i == len(EIR_Dataset):\n",
    "        break\n",
    "    # for j in range(len(selected_trials)):\n",
    "        # if i[9] == 'g' and i[2] == selected_subjects[j] and i[3] == selected_trials[j]:\n",
    "    power_wav.append(sample[0][:, :, :max_len])\n",
    "    phase_wav.append(sample[1][:, :, :max_len])\n",
    "    subj.append(sample[2])\n",
    "    trial.append(sample[3])\n",
    "    label_wav.append(sample[7])\n",
    "    \n",
    "power_wav = np.array(power_wav)\n",
    "phase_wav = np.array(phase_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843a820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 63, 195, 309)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4529853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 63, 195, 309)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da85c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_wav_combined = power_wav.transpose(0, 2, 1, 3).reshape(power_wav.shape[0], power_wav.shape[1], power_wav.shape[2]*power_wav.shape[3])\n",
    "phase_wav_combined = phase_wav.transpose(0, 2, 1, 3).reshape(phase_wav.shape[0], phase_wav.shape[1], phase_wav.shape[2]*phase_wav.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ee11e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 63, 60255)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_wav_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from Scripts import Selectors_From_Dataset as sel\n",
    "X, img, y = sel.get_sample(EIR_Dataset)\n",
    "\n",
    "def take_subset(n=20, random_state=42, *args):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    N = len(y)\n",
    "    n = min(n, N)\n",
    "    idx = rng.choice(N, size=n, replace=False)\n",
    "\n",
    "    returnable = []\n",
    "    for value in args:\n",
    "        returnable.append(value[idx])\n",
    "\n",
    "    return returnable\n",
    "\n",
    "# X, y, power_wav_combined, phase_wav_combined, label_wav = take_subset(20, 123, X, y, power_wav_combined, phase_wav_combined, np.array(label_wav))\n",
    "# subjects_cluster3 = [7, 7, 9, 9, 14]\n",
    "# trial_cluster3 = [2, 1, 2, 1, 1]\n",
    "# subjects_cluster4 = [5, 5, 3, 3, 2, 2, 10, 10, 12, 12, 16, 16, 11, 11, 13, 13]\n",
    "# trial_cluster4 = [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]\n",
    "# X, img, y = sel.get_sample_choosen_trial(EIR_Dataset, subjects_cluster4 + subjects_cluster3, trial_cluster4 + trial_cluster3)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test, power_wav_train, power_wav_test, phase_wav_train, phase_wav_test, y_wav_train, y_wav_test = train_test_split(\n",
    "#     X, y, power_wav_combined, phase_wav_combined, np.array(label_wav), test_size=0.5, stratify=y, random_state=40, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffa418e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 63, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a0e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pyriemann.estimation import Covariances\n",
    "from typing import Union\n",
    "\n",
    "n_components = 4\n",
    "class ModelCovariance:\n",
    "    class ParallelCovariances(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, n_filters, covariance_type: Union[list, type] = Covariances):\n",
    "            self.covariance_type = covariance_type\n",
    "            self.n_filters = n_filters\n",
    "            self.cov = []\n",
    "            self.cov_pipeline = []\n",
    "\n",
    "            for i, cov_type in enumerate(covariance_type):\n",
    "                if cov_type == XdawnCovariances:\n",
    "                    self.cov.append(cov_type(nfilter = self.n_filters[i], estimator = 'lwf', xdawn_estimator='lwf'))\n",
    "                else: self.cov.append(cov_type(estimator = 'lwf'))\n",
    "        def fit(self, X, y):\n",
    "            self.cov_pipeline = []\n",
    "            for i in range(len(X)):\n",
    "                self.cov_pipeline.append(Pipeline([\n",
    "                ('covariance', self.cov[i]),\n",
    "                ('tangent', TangentSpace())]))\n",
    "                self.cov_pipeline[i].fit(X[i], y)\n",
    "            return self\n",
    "        \n",
    "        def transform(self, X):\n",
    "            ret = []\n",
    "            for i in range(len(X)):\n",
    "                ret.append(self.cov_pipeline[i].transform(X[i]))\n",
    "            combined = np.concatenate(ret, axis=1)\n",
    "            return combined\n",
    "\n",
    "        \n",
    "    def __init__(self, feature_groups: int = 3, n_filters: Union[list, int, None] = 4, covariances: Union[list, type] = XdawnCovariances,\n",
    "                  Classifier: Union[list, BaseEstimator] = LogisticRegression(C=3, class_weight='balanced', max_iter = 300)):\n",
    "        self.feature_groups = feature_groups\n",
    "        self.covariances = covariances\n",
    "        self.n_filters = n_filters\n",
    "        if feature_groups == 1: # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è —á—Ç–æ –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –Ω–∏–≥–¥–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è list –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "            cov = covariances(estimator='lwf')\n",
    "            if covariances == XdawnCovariances:\n",
    "                cov = covariances(n_filters, estimator='lwf', xdawn_estimator='lwf')\n",
    "            self.pipeline = Pipeline([\n",
    "                ('cov', cov),\n",
    "                ('tang', TangentSpace()),\n",
    "                ('clf', Classifier)])\n",
    "        else: # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–∏—Å—Ç—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ - —Å–ª–µ–¥–∏–º —á—Ç–æ–±—ã –¥–ª–∏–Ω–∞ —Å–æ–≤–ø–∞–¥–∞–ª–∞ —Å feature_groups\n",
    "            if isinstance(n_filters, int):\n",
    "                self.n_filters = [n_filters] * feature_groups\n",
    "            if isinstance(covariances, type):\n",
    "                self.covariances = [covariances] * feature_groups\n",
    "            self.pipeline = (Pipeline([\n",
    "                ('cov', self.ParallelCovariances(self.n_filters, self.covariances)),\n",
    "                ('clf', Classifier)]))\n",
    "    def get_pipeline(self):\n",
    "        return self.pipeline\n",
    "    def fit(self, X, y):\n",
    "        self.pipeline.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.pipeline.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, true_y, metric: Union[str, list] = 'accuracy'):\n",
    "        preds = self.pipeline.predict(X)\n",
    "        if isinstance(metric, str):\n",
    "            if metric == 'accuracy':\n",
    "                return metrics.accuracy_score(true_y, preds)\n",
    "            elif metric == 'precision':\n",
    "                return metrics.precision_score(true_y, preds, average='weighted')\n",
    "            elif metric == 'recall':\n",
    "                return metrics.recall_score(true_y, preds, average='weighted')\n",
    "            elif metric == 'f1':\n",
    "                return metrics.f1_score(true_y, preds, average='weighted')\n",
    "            elif metric == 'roc_auc':\n",
    "                return metrics.roc_auc_score(true_y, preds)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown metric: {metric}\")\n",
    "        \n",
    "        elif isinstance(metric, list):\n",
    "            results = {}\n",
    "            for m in metric:\n",
    "                if m == 'accuracy':\n",
    "                    results[m] = metrics.accuracy_score(true_y, preds)\n",
    "                elif m == 'precision':\n",
    "                    results[m] = metrics.precision_score(true_y, preds, average='weighted')\n",
    "                elif m == 'recall':\n",
    "                    results[m] = metrics.recall_score(true_y, preds, average='weighted')\n",
    "                elif m == 'f1':\n",
    "                    results[m] = metrics.f1_score(true_y, preds, average='weighted')\n",
    "                elif m == 'roc_auc':\n",
    "                    results[m] = metrics.roc_auc_score(true_y, preds)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown metric: {m}\")\n",
    "            return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736e17a",
   "metadata": {},
   "source": [
    "###  Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12fd7516-2ed2-4145-bfba-10b05a7d100a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from tqdm import tqdm\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # –í—Å—Ç–∞–≤—å —Å—é–¥–∞ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ: X, y, power_wav_combined, phase_wav_combined, label_wav\n",
    "# # from your_data_module import X, y, power_wav_combined, phase_wav_combined, label_wav\n",
    "\n",
    "# random_states = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "# test_sizes = [0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.7]\n",
    "\n",
    "# # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫\n",
    "# results_storage = {\n",
    "#     1: [],\n",
    "#     2: [],\n",
    "#     3: [],\n",
    "#     4: [],\n",
    "#     5: []\n",
    "# }\n",
    "\n",
    "# # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–æ –≤—Å–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—è–º\n",
    "# for random_state, test_size in tqdm(list(product(random_states, test_sizes))):\n",
    "#     try:\n",
    "#         # –°–ø–ª–∏—Ç–∏–º –¥–∞–Ω–Ω—ã–µ\n",
    "#         X_train, X_test, Y_train, Y_test, power_wav_train, power_wav_test, phase_wav_train, phase_wav_test, y_wav_train, y_wav_test = train_test_split(\n",
    "#             X, y, power_wav_combined, phase_wav_combined, np.array(label_wav),\n",
    "#             test_size=test_size, stratify=y, random_state=random_state\n",
    "#         )\n",
    "    \n",
    "#         # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏\n",
    "#         models = {\n",
    "#             1: ModelCovariance(feature_groups=1, n_filters=4,\n",
    "#                                covariances=XdawnCovariances,\n",
    "#                                Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "#             2: ModelCovariance(feature_groups=3, n_filters=4,\n",
    "#                                covariances=[XdawnCovariances, Covariances, Covariances],\n",
    "#                                Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "#             3: ModelCovariance(feature_groups=2, n_filters=4,\n",
    "#                                covariances=[XdawnCovariances, Covariances],\n",
    "#                                Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "#             4: ModelCovariance(feature_groups=2, n_filters=4,\n",
    "#                                covariances=[XdawnCovariances, Covariances],\n",
    "#                                Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "#             5: ModelCovariance(feature_groups=2, n_filters=4,\n",
    "#                                covariances=[Covariances, Covariances],\n",
    "#                                Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "#         }\n",
    "    \n",
    "#         inputs_train = {\n",
    "#             1: X_train,\n",
    "#             2: [X_train, power_wav_train, phase_wav_train],\n",
    "#             3: [X_train, power_wav_train],\n",
    "#             4: [X_train, phase_wav_train],\n",
    "#             5: [power_wav_train, phase_wav_train]\n",
    "#         }\n",
    "    \n",
    "#         inputs_test = {\n",
    "#             1: X_test,\n",
    "#             2: [X_test, power_wav_test, phase_wav_test],\n",
    "#             3: [X_test, power_wav_test],\n",
    "#             4: [X_test, phase_wav_test],\n",
    "#             5: [power_wav_test, phase_wav_test]\n",
    "#         }\n",
    "    \n",
    "#         # –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
    "#         for i in range(1, 6):\n",
    "#             models[i].fit(inputs_train[i], Y_train)\n",
    "#             results = models[i].evaluate(inputs_test[i], Y_test, ['accuracy', 'f1'])\n",
    "#             results_storage[i].append({\n",
    "#                 'random_state': random_state,\n",
    "#                 'test_size': test_size,\n",
    "#                 'accuracy': results['accuracy'],\n",
    "#                 'f1': results['f1']\n",
    "#             })\n",
    "#     except Exception as e:\n",
    "#         print(f\"ERROR AT: random_state={random_state}, test_size={test_size}.\\nERROR:{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbaae45",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7cca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [27:24<00:00, 149.49s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "random_states = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "n_splits = 3\n",
    "\n",
    "results_storage = {\n",
    "    1: [],\n",
    "    2: [],\n",
    "    3: [],\n",
    "    4: [],\n",
    "    5: []\n",
    "}\n",
    "\n",
    "metrics_list = ['accuracy', 'f1']\n",
    "\n",
    "models = {\n",
    "                1: ModelCovariance(feature_groups=1, n_filters=4,\n",
    "                                    covariances=XdawnCovariances,\n",
    "                                    Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "                2: ModelCovariance(feature_groups=3, n_filters=4,\n",
    "                                    covariances=[XdawnCovariances, Covariances, Covariances],\n",
    "                                    Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "                3: ModelCovariance(feature_groups=2, n_filters=4,\n",
    "                                    covariances=[XdawnCovariances, Covariances],\n",
    "                                    Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "                4: ModelCovariance(feature_groups=2, n_filters=4,\n",
    "                                    covariances=[XdawnCovariances, Covariances],\n",
    "                                    Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "                5: ModelCovariance(feature_groups=2, n_filters=4,\n",
    "                                    covariances=[Covariances, Covariances],\n",
    "                                    Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter=300)),\n",
    "            }\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ‚Äî —Ç–µ–ø–µ—Ä—å –ø–æ random_state (–∫–∞–∂–¥—ã–π –∑–∞–¥–∞—ë—Ç —Ä–∞–∑–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ñ–æ–ª–¥–æ–≤)\n",
    "for random_state in tqdm(random_states):\n",
    "    try:\n",
    "        k_fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "        for train_index, test_index in k_fold.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = y[train_index], y[test_index]\n",
    "            power_wav_train, power_wav_test = power_wav_combined[train_index], power_wav_combined[test_index]\n",
    "            phase_wav_train, phase_wav_test = phase_wav_combined[train_index], phase_wav_combined[test_index]\n",
    "            y_wav_train, y_wav_test = np.array(label_wav)[train_index], np.array(label_wav)[test_index]\n",
    "\n",
    "            inputs_train = {\n",
    "                1: X_train,\n",
    "                2: [X_train, power_wav_train, phase_wav_train],\n",
    "                3: [X_train, power_wav_train],\n",
    "                4: [X_train, phase_wav_train],\n",
    "                5: [power_wav_train, phase_wav_train]\n",
    "            }\n",
    "\n",
    "            inputs_test = {\n",
    "                1: X_test,\n",
    "                2: [X_test, power_wav_test, phase_wav_test],\n",
    "                3: [X_test, power_wav_test],\n",
    "                4: [X_test, phase_wav_test],\n",
    "                5: [power_wav_test, phase_wav_test]\n",
    "            }\n",
    "\n",
    "            # –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
    "            for i in range(1, 6):\n",
    "                models[i].fit(inputs_train[i], Y_train)\n",
    "                results = models[i].evaluate(inputs_test[i], Y_test, metrics_list)\n",
    "                \n",
    "                storage_item = {\n",
    "                    'random_state': random_state,\n",
    "                    'fold': len(results_storage[i]) % n_splits + 1}\n",
    "                for metric in metrics_list:\n",
    "                    storage_item[metric] = results[metric]\n",
    "                    \n",
    "                results_storage[i].append(storage_item)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR AT: random_state={random_state}.\\nERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4647059",
   "metadata": {},
   "source": [
    "### Remaining code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ececa0-b10a-4ae7-9dcd-e27e9380a682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     40\u001b[39m     fig.update_layout(\n\u001b[32m     41\u001b[39m         scene=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     42\u001b[39m             xaxis_title=\u001b[33m'\u001b[39m\u001b[33mRandom State\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m         margin=\u001b[38;5;28mdict\u001b[39m(l=\u001b[32m0\u001b[39m, r=\u001b[32m0\u001b[39m, b=\u001b[32m0\u001b[39m, t=\u001b[32m40\u001b[39m)\n\u001b[32m     48\u001b[39m     )\n\u001b[32m     50\u001b[39m     fig.write_html(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mf1_xDAWN_LR_Exp\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_(ALL_SAMPLES).html\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Data/File_Storage/Code/ML/EEG-Image-Reconstruction-fork/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Data/File_Storage/Code/ML/EEG-Image-Reconstruction-fork/.venv/lib/python3.12/site-packages/plotly/io/_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "metric = 'f1'\n",
    "if metric not in metrics_list:\n",
    "    print(f\"ERROR: {metric} is not in metrics_list and has not been evaluzted\")\n",
    "\n",
    "# –í—ã–±–∏—Ä–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "for i in range(1, 6):\n",
    "    exp = i  # –æ—Ç 1 –¥–æ 5\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    f1_data = results_storage[exp]\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –æ—Å—è–º\n",
    "    random_states_unique = sorted(set(m['random_state'] for m in f1_data))\n",
    "    test_sizes_unique = sorted(set(m['fold'] for m in f1_data))\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞—Ç—Ä–∏—Ü—É f1_scores (–æ—Å—å Y ‚Äî test_size, –æ—Å—å X ‚Äî random_state)\n",
    "    Z = np.zeros((len(test_sizes_unique), len(random_states_unique)))\n",
    "    \n",
    "    # –ó–∞–ø–æ–ª–Ω—è–µ–º –º–∞—Ç—Ä–∏—Ü—É Z\n",
    "    for m in f1_data:\n",
    "        i = test_sizes_unique.index(m['fold'])\n",
    "        j = random_states_unique.index(m['random_state'])\n",
    "        Z[i, j] = m[metric]\n",
    "    \n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ 3D –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏\n",
    "    fig = go.Figure(data=[\n",
    "        go.Surface(\n",
    "            z=Z,\n",
    "            x=random_states_unique,\n",
    "            y=test_sizes_unique,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title=f'{metric} Score'),\n",
    "            showscale=True\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='Random State',\n",
    "            yaxis_title='Test Size',\n",
    "            zaxis_title=f'{metric} Score'\n",
    "        ),\n",
    "        title=f'{metric} Score Surface for Experiment {exp}',\n",
    "        margin=dict(l=0, r=0, b=0, t=40)\n",
    "    )\n",
    "    \n",
    "    fig.write_html(f\"f1_xDAWN_LR_Exp{exp}_(ALL_SAMPLES).html\")\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78de8633-1ed1-4b36-b5b8-503d30747a70",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Generated/Figures/Classification/f1_xDAWN_LR_Exp1_(ALL_SAMPLES).html'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_name, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(file_names, labels):\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# 1. –°—á–∏—Ç–∞—Ç—å HTML\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     36\u001b[39m         html = f.read()\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# 2. –ù–∞–π—Ç–∏ Plotly JSON\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Data/File_Storage/Code/ML/EEG-Image-Reconstruction-fork/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './Generated/Figures/Classification/f1_xDAWN_LR_Exp1_(ALL_SAMPLES).html'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import base64\n",
    "import os\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ HTML-—Ñ–∞–π–ª–∞–º\n",
    "base_path = \"./Generated/Figures/Classification\"\n",
    "file_names = [\n",
    "    f\"{metric}_xDAWN_LR_Exp1_(ALL_SAMPLES).html\",\n",
    "    f\"{metric}_xDAWN_LR_Exp2_(ALL_SAMPLES).html\",\n",
    "    f\"{metric}_xDAWN_LR_Exp3_(ALL_SAMPLES).html\",\n",
    "    f\"{metric}_xDAWN_LR_Exp4_(ALL_SAMPLES).html\",\n",
    "    f\"{metric}_xDAWN_LR_Exp5_(ALL_SAMPLES).html\"\n",
    "]\n",
    "\n",
    "# –ù–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ª–µ–≥–µ–Ω–¥—ã\n",
    "labels = ['EEG',\n",
    "          'EEG + Power + Phase',\n",
    "          'EEG + Power',\n",
    "          'EEG + Phase',\n",
    "          'Power + Phase']\n",
    "\n",
    "# –°–ø–∏—Å–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö –∏ std\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "for file_name, label in zip(file_names, labels):\n",
    "    # 1. –°—á–∏—Ç–∞—Ç—å HTML\n",
    "    with open(os.path.join(base_path, file_name), encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    # 2. –ù–∞–π—Ç–∏ Plotly JSON\n",
    "    pattern = re.compile(r'Plotly\\.newPlot\\([^,]+,\\s*(\\[\\{.*?\\}\\])', re.DOTALL)\n",
    "    match = pattern.search(html)\n",
    "    if not match:\n",
    "        print(f\"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω Plotly JSON –≤ —Ñ–∞–π–ª–µ {file_name}\")\n",
    "        continue\n",
    "\n",
    "    plot_data_json = match.group(1)\n",
    "    plot_data = json.loads(plot_data_json)[0]\n",
    "\n",
    "    x = plot_data['x']\n",
    "    y = plot_data['y']\n",
    "    z_meta = plot_data['z']\n",
    "\n",
    "    # 3. –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å z\n",
    "    z_bytes = base64.b64decode(z_meta['bdata'])\n",
    "    z_array = np.frombuffer(z_bytes, dtype=z_meta['dtype'])\n",
    "    z = z_array.reshape(tuple(map(int, z_meta['shape'].split(','))))\n",
    "\n",
    "    # 4. –°—Ä–µ–¥–Ω–µ–µ –ø–æ X (axis=1)\n",
    "    z_avg_by_y = z.mean(axis=1)\n",
    "\n",
    "    # 5. –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å\n",
    "    plt.plot(y, z_avg_by_y, marker='o', label=label)\n",
    "\n",
    "    # 6. –ü–æ—Å—á–∏—Ç–∞—Ç—å –æ–±—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏ std –ø–æ –≤—Å–µ–π –º–∞—Ç—Ä–∏—Ü–µ z\n",
    "    z_mean = z.mean()\n",
    "    z_std = z.std()\n",
    "    means.append(z_mean)\n",
    "    stds.append(z_std)\n",
    "\n",
    "# –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "plt.xlabel(\"Test Size\")\n",
    "plt.ylabel(f\"Average {metric} Score\")\n",
    "plt.title(f\"{metric} Score vs Test Size\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ü–µ—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(f\"\\nüìä Mean {metric} scores:\")\n",
    "for label, mean in zip(labels, means):\n",
    "    print(f\"{label}: {mean:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Std {metric} scores:\")\n",
    "for label, std in zip(labels, stds):\n",
    "    print(f\"{label}: {std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ccb8f3-5533-48a0-ae22-ca1d661ddb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
